# Pretraining

Study pretraining strategies for NLP models, where models learn from large unlabeled corpora before fine-tuning. Pretraining is key to modern NLP success.

**Key topics:**
- Language model pretraining
- Transfer learning
- Benefits for downstream tasks 